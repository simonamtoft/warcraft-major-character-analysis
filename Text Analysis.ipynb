{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import community\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import config\n",
    "from text_helpers import init_collection, populate_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and import \"book\"\n",
    "nltk.download('book', quiet=True)\n",
    "from nltk import book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Faction</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A'dal</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Naaru</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aegwynn</td>\n",
       "      <td>Female</td>\n",
       "      <td>Human</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Deceased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aessina</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wisp</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Agamaggan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Boar</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Deceased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Agatha</td>\n",
       "      <td>Female</td>\n",
       "      <td>Val'Kyr</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Deceased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name   Gender     Race  Faction    Status\n",
       "0      A'dal  Unknown    Naaru  Neutral     Alive\n",
       "2    Aegwynn   Female    Human  Neutral  Deceased\n",
       "3    Aessina   Female     Wisp  Neutral   Unknown\n",
       "5  Agamaggan     Male     Boar  Neutral  Deceased\n",
       "6     Agatha   Female  Val'Kyr  Neutral  Deceased"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of all characters which \n",
    "chars_with_comments = [\n",
    "    path.split('\\\\')[-1].replace('.njson', '') \n",
    "    for path in glob('./data/char_comments/*.njson')\n",
    "]\n",
    "\n",
    "# read in character DataFrame\n",
    "df = pd.read_csv(config.PATH_RES + 'df_chars.csv')\n",
    "\n",
    "# remove chars that doesn't have comments from wowhead\n",
    "df = df[df['Name'].apply(lambda n: n in chars_with_comments)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of\n",
      "Nodes: 239\n",
      "Edges: 2410\n"
     ]
    }
   ],
   "source": [
    "# load graph\n",
    "Gcc = nx.read_gexf(config.PATH_RES + 'Gcc_wow.gexf').to_undirected()\n",
    "\n",
    "# remove nodes from graph that doesn't have comments from wowhead\n",
    "for node in list(Gcc.nodes()):\n",
    "    if node.replace(' ', '_') not in chars_with_comments:\n",
    "        Gcc.remove_node(node)\n",
    "\n",
    "print(f'Number of\\nNodes: {len(list(Gcc.nodes()))}\\nEdges: {len(list(Gcc.edges()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Communities\n",
    "Create or load community partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing community partition.\n",
      "from pickle ./store/Communities.json\n"
     ]
    }
   ],
   "source": [
    "# create communities if not done already, otherwise load\n",
    "filename = config.PATH_RES + 'Communities.json'\n",
    "if not os.path.isfile(filename):\n",
    "    print('Creating new community partition.')\n",
    "    partition = community.best_partition(Gcc)\n",
    "    communities = []\n",
    "    for p in set(partition.values()):\n",
    "        names = [n for n in partition if partition[n] == p]\n",
    "        communities.append(names)\n",
    "    pickle.dump(communities, open(filename, 'wb'))\n",
    "    print(f'Saved as pickle {filename}')\n",
    "else: \n",
    "    print('Loading existing community partition.')\n",
    "    print(f'from pickle {filename}')\n",
    "    communities = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# get top chars in each community\n",
    "degs = list(Gcc.degree())\n",
    "com_names = []\n",
    "for com in communities:\n",
    "    com_sorted = sorted([(n, v) for n, v in degs if n in com], key=lambda x: x[1], reverse=True)\n",
    "    top_names = [n for n, _ in com_sorted[:3]]\n",
    "    com_name = ', '.join(top_names)\n",
    "    com_names.append(com_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Corpus etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word files for wowpedia character pages\n",
    "file_list = [config.PATH_WORDS + n + '.txt' for n in chars_with_comments]\n",
    "c_words_wiki = nltk.corpus.PlaintextCorpusReader('', file_list)\n",
    "t_words_wiki = nltk.Text(c_words_wiki.words())\n",
    "\n",
    "# word files for wowhead user comments\n",
    "file_list = [config.PATH_COMMENTS_WORDS + n + '.txt' for n in chars_with_comments]\n",
    "c_words_comments = nltk.corpus.PlaintextCorpusReader('', file_list)\n",
    "t_words_comments = nltk.Text(c_words_wiki.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what to look into\n",
    "attr_lookup = {\n",
    "    'Gender': [('Male', '#0B1C51'), ('Female', '#FCB9B2')],\n",
    "    'Faction': [('Alliance', config.COLOR_ALLIANCE), ('Horde', config.COLOR_HORDE)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doing Gender for wowpedia/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 3/3 [03:45<00:00, 75.26s/it]\n",
      "Computing wordclouds: 100%|██████████| 3/3 [00:00<00:00, 39.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doing Faction for wowpedia/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 3/3 [03:22<00:00, 67.51s/it]\n",
      "Computing wordclouds: 100%|██████████| 3/3 [00:00<00:00, 69.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doing Gender for wowhead/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 3/3 [07:54<00:00, 158.30s/it]\n",
      "Computing wordclouds: 100%|██████████| 3/3 [00:00<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Doing Faction for wowhead/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 3/3 [06:36<00:00, 132.02s/it]\n",
      "Computing wordclouds: 100%|██████████| 3/3 [00:00<00:00, 18.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# create collections for attributes for both wowpedia pages and wowhead comments\n",
    "for source, corpus, path_words in [\n",
    "    ('wowpedia/', c_words_wiki, config.PATH_WORDS), \n",
    "    ('wowhead/', c_words_comments, config.PATH_COMMENTS_WORDS)\n",
    "]:\n",
    "    for attr in attr_lookup:\n",
    "        # check if collection already is created\n",
    "        save_path = config.PATH_RES + source + attr + '_dict.json'\n",
    "        if os.path.isfile(save_path):\n",
    "            print(f'\\nSkipping {attr} for {source} since it is already done.')\n",
    "            continue\n",
    "        else:\n",
    "            print(f'\\nDoing {attr} for {source}')\n",
    "        \n",
    "        # create collection and save it\n",
    "        col = init_collection(df, attr, path_words, corpus)\n",
    "        _ = populate_collection(col, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing collections for communities for wowpedia/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 7/7 [14:48<00:00, 126.97s/it]\n",
      "Computing wordclouds: 100%|██████████| 7/7 [00:00<00:00, 142.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing collections for communities for wowhead/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing values: 100%|██████████| 7/7 [12:39<00:00, 108.44s/it]\n",
      "Computing wordclouds: 100%|██████████| 7/7 [00:00<00:00, 107.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# create collections for communities for both wowpedia pages and wowhead comments\n",
    "for source, corpus, path_words in [\n",
    "    ('wowpedia/', c_words_wiki, config.PATH_WORDS), \n",
    "    ('wowhead/', c_words_comments, config.PATH_COMMENTS_WORDS)\n",
    "]:  \n",
    "    print(f'Computing collections for communities for {source}')\n",
    "    col = {}\n",
    "    save_path = config.PATH_RES + source + 'Louvain_dict.json'\n",
    "    if os.path.isfile(save_path):\n",
    "        continue\n",
    "\n",
    "    for i, names in enumerate(communities): \n",
    "        paths = [\n",
    "            path_words + n.replace(' ', '_') + '.txt' \n",
    "            for n in names\n",
    "        ]\n",
    "        # save text for community\n",
    "        col[i] = {'text': nltk.Text(corpus.words(paths))}\n",
    "    \n",
    "    # create collection and save it\n",
    "    col = populate_collection(col, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Words\n",
    "Inspect top 5 words according to tf-idf for each attribute split and for the different communities by Louvain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For wowpedia/\n",
      "\n",
      "Top 5 for attribute Gender\n",
      "\tMale: rexxar, voljin, demon, mannoroth, drekthar\n",
      "\tFemale: ysera, elune, draka, talanji, aegwynn\n",
      "\n",
      "Top 5 for attribute Faction\n",
      "\tAlliance: turalyon, antonidas, thassarian, koltira, faol\n",
      "\tHorde: rokhan, rexxar, nazgrel, bwonsamdi, eitrigg\n",
      "\n",
      "\n",
      "For wowhead/\n",
      "\n",
      "Top 5 for attribute Gender\n",
      "\tMale: razorgore, anzu, voljin, amalgamation, rexxar\n",
      "\tFemale: whelp, onyxian, yula, lift, ony\n",
      "\n",
      "Top 5 for attribute Faction\n",
      "\tAlliance: thassarian, koltira, skybreaker, lurid, naaru\n",
      "\tHorde: rexxar, blackhand, rokhan, ya, troll\n"
     ]
    }
   ],
   "source": [
    "# display top words for attributes\n",
    "for source in ['wowpedia/', 'wowhead/']:\n",
    "    print(f\"\\n\\nFor {source}\")\n",
    "    for attr in attr_lookup:\n",
    "        print(f'\\nTop 5 for attribute {attr}')\n",
    "        col = pickle.load(open(config.PATH_RES + source + attr + '_dict.json', 'rb'))\n",
    "        for split, _ in attr_lookup[attr]:\n",
    "            top_5 = ', '.join(col[split]['words'][np.argsort(col[split]['tfidf'])[::-1]][:5])\n",
    "            print(f'\\t{split}: {top_5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For wowpedia/\n",
      "Top 5 words for each community\n",
      "\n",
      "\"Khadgar, Illidan Stormrage, Velen\"\n",
      "halduron, lorthemar, alleria, rommath, muru\n",
      "\n",
      "\"Deathwing, Sargeras, Yogg-Saron\"\n",
      "odyn, tyr, mimiron, thorim, nefarian\n",
      "\n",
      "\"Sylvanas Windrunner, Lich King, Varian Wrynn\"\n",
      "thassarian, koltira, darion, sylvanas, alexandros\n",
      "\n",
      "\"Malfurion Stormrage, Tyrande Whisperwind, Alexstrasza\"\n",
      "malorne, jarod, aviana, eranikus, tyrande\n",
      "\n",
      "\"Thrall, Ner'zhul, Orgrim Doomhammer\"\n",
      "draka, horde, drekthar, maraad, orgrim\n",
      "\n",
      "\"Anzu, Terokk, Talon King Ikiss\"\n",
      "ikiss, terokk, anzu, terokks, rukhmar\n",
      "\n",
      "\"Jaina Proudmoore, Anduin Wrynn, Garrosh Hellscream\"\n",
      "li, chen, garrosh, voljin, horde\n",
      "\n",
      "\n",
      "For wowhead/\n",
      "Top 5 words for each community\n",
      "\n",
      "\"Khadgar, Illidan Stormrage, Velen\"\n",
      "gravity, lapse, capernian, pyroblast, phoenix\n",
      "\n",
      "\"Deathwing, Sargeras, Yogg-Saron\"\n",
      "amalgamation, whelp, thorim, ony, tendon\n",
      "\n",
      "\"Sylvanas Windrunner, Lich King, Varian Wrynn\"\n",
      "darion, lich, frostmourne, arthas, thassarian\n",
      "\n",
      "\"Malfurion Stormrage, Tyrande Whisperwind, Alexstrasza\"\n",
      "drelanim, jarod, malorne, ursoc, kariel\n",
      "\n",
      "\"Thrall, Ner'zhul, Orgrim Doomhammer\"\n",
      "blackhand, kargath, drekthar, gall, margok\n",
      "\n",
      "\"Anzu, Terokk, Talon King Ikiss\"\n",
      "anzu, terokk, ikiss, anzus, sethekk\n",
      "\n",
      "\"Jaina Proudmoore, Anduin Wrynn, Garrosh Hellscream\"\n",
      "razorgore, plushie, xu, chen, yula\n"
     ]
    }
   ],
   "source": [
    "# display top words per community\n",
    "for source in ['wowpedia/', 'wowhead/']:\n",
    "    print(f\"\\n\\nFor {source}\")\n",
    "    print(f'Top 5 words for each community')\n",
    "    col = pickle.load(open(config.PATH_RES + source + 'Louvain_dict.json', 'rb'))\n",
    "    for i, com_name in enumerate(com_names):\n",
    "        print(f'\\n\"{com_name}\"')\n",
    "        words = col[i]['words']\n",
    "        tfidf = col[i]['tf'] * col[i]['idf']\n",
    "        top_5 = ', '.join(words[np.argsort(tfidf)[::-1]][:5])\n",
    "        print(top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c8b715ef500c155f7e623c10e2a2705ee7484473bce4c48cafd25806eafb59b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
